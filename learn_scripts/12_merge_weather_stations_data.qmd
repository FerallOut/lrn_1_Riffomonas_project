---
title: '12_merge_weather_regions_data'
date: "18.Aug.2025"
date-modified: "today"
date-format: "DD.MMM.YYYY"
execute:
  echo: true
  warning: false
  #message: false

from: markdown+emoji
categories: [snakemake, rounding_numbers]
toc: true
toc-title: "Index"
smooth-scroll: true
toc-depth: 3
#fig-dpi: 300
format:
  html:
    embed-resources: true
    df-print: kable
    page-layout: full
    #code-overflow: wrap
    fig-width: 8
    fig-height: 6
code-line-numbers: true
number-sections: true
## to wrap output
include-in-header:
  - text: |
      <style>
      .cell-output-stdout code {
        word-break: break-wor !important;
        white-space: pre-wrap !important;
      }
      </style>
---

```{r}
#| label: setup
#| echo: false

all_times <- list()  # store the time for each chunk

knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      now <<- Sys.time()
    } else {
      res <- difftime(Sys.time(), now, units = "mins")
      all_times[[options$label]] <<- res
    }
  }
})
)

knitr::opts_chunk$set(
  # don't use, has issues with a lot of symbols
  # https://yihui.org/formatr/
  #tidy = TRUE,
  time_it = TRUE,
  fig.align = 'center',
  highlight = TRUE, 
  cache.lazy = FALSE,
  #comment = "#>",
  collapse = TRUE
)

## to crop the empty white space around the pdf plots
knitr::knit_hooks$set(crop = knitr::hook_pdfcrop)
```

```{r}
#| label: libraries_packages
#| output: false

## conda env: ./env_tar/smk_env1/

x <- c("tidyverse", "magrittr")

## Load libraries
invisible(lapply(x, library, character.only = TRUE))
```


# load data

```{r}

prcp_data <- read_tsv("../data/9_ghcnd_tidy.tsv.gz") %T>% 
  {head(.) %>% print()} %T>%
  {dim(.) %>% print()} 

region_data <- read_tsv("../data/11_ghcnd_regions_years.tsv") %T>% 
  {head(.) %>% print()} %T>%
  {dim(.) %>% print()} 
```

# test joining

```{r}
inner_join(prcp_data, 
           region_data,
           by = "id") %T>%
  {head(.) %>% print()}

## what about the data without correspondence?

## values in "prcp_data" not in "region_data"
anti_join(prcp_data, 
          region_data,
          by = "id") %T>% 
  {head(.) %>% print()} %>%
  {dim(.) %>% print()} 
## very few missing data for those regions (3 out of 3.269.055)

## values in "region_data" not in "prcp_data"
anti_join(region_data,
          prcp_data,
          by = "id") %T>% 
  {head(.) %>% print()} %>%
  {dim(.) %>% print()} 
## same (675 out of 127.608)

## come back to comb through these values if you see wholes in the map at the end 
```


# Summarize mean precipitation by region and year

Remove partial data (where the year is not whole)

```{r}
## remove regions where you have partial data BUT keep the last year you have on record

## what is the last year?
last_yr <- inner_join(prcp_data, 
           region_data,
           by = "id") %>%  
  arrange(desc(year)) %>% 
  slice_head(n=1) %>% 
  pull(year) 


lat_log_prcp <- inner_join(prcp_data, 
           region_data,
           by = "id") %T>% 
  {head(.) %>% print()} %T>%
  {dim(.) %>% print()} %>% 
  filter( (year != first_year & year != last_year) | year == last_yr) %>% 
  ## group by region; add the rest of the variables to keep them
  ## region is not really necessary in this analysis
  #group_by(region, latitude, longitude, year) %>% 
  group_by(latitude, longitude, year) %>% 
  summarize(mean_prcp = mean(prcp)) %T>%
  {head(.) %>% print()} %T>%
  dim() 
  
lat_log_prcp %>% 
  ## from how many locations do we have data?
  summarize(n = n()) %T>%
  {head(.) %>% print()} %T>%
  {dim(.) %>% print()} 
```

# result exploration

## basic plotting

There is a bimodal distribution

```{r}
lat_log_prcp %>% 
  ## from how many locations do we have data?
  summarize(n = n()) %>% 
  ggplot(aes(x=n)) + 
  geom_histogram()
```

```{r}

## how many regions with more than 100 observations
lat_log_prcp %>% 
  summarize(n = n()) %>% 
  filter(n >= 100) %T>%
  {head(.) %>% print()} %>% 
  dim()
```


# calculate the Z-score statistics for each region for 2025

You need the mean and stdev, and to make sure to keep all the regions with precipitation data for 2025.

## get 2025 (last year's) precipitation and that of all years

```{r}
## get regions (lat + long) that have data for 2025
this_year <- lat_log_prcp %>% 
  filter(year == last_yr) %>% 
  select(-year)

inner_join(lat_log_prcp, 
           this_year,
           by = c("latitude", "longitude") ) %>% 
  rename(all_years = mean_prcp.x,
         year_2025 = mean_prcp.y) %>% 
  head()

# didn't check further
# anti_join(lat_log_prcp, 
#            this_year,
#            by = c("latitude", "longitude") )
# 
# anti_join(this_year,
#            lat_log_prcp, 
#            by = c("latitude", "longitude") )
```

## get Z-score

```{r}
inner_join(lat_log_prcp, 
           this_year,
           by = c("latitude", "longitude") ) %>% 
  rename(all_years = mean_prcp.x,
         year_2025 = mean_prcp.y) %>% 
  group_by(latitude, longitude) %>% 
  mutate(nr_of_years = n()) %T>%
  {head(.) %>% print()} %>% 
  
  ## each region has various years
  ## set threshold for e.g. 20 years
  ## play around with the threshold
  filter(nr_of_years >= 50) %>% 
  #mutate(z_score = (min(this_year) - mean(all_years))/sd(all_years))
  ##use summarize instead - why?
  summarize(z_score = (last_yr - mean(all_years))/sd(all_years),
            .groups = "drop")

```


# Save time

```{r}
#| label: save_times

t(as.data.frame(all_times))
```

# Session information

```{r}
#| label: sessionInfo

sessionInfo()
```
